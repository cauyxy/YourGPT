{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc9334ab-fd1b-42e5-9d67-3323697b607c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import BloomForCausalLM, BloomTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ecb017b-f951-4e02-90fb-c919cf41bdb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_input_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb875c40-821b-4764-b7bb-febff037be77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROMPT_DICT = {\n",
    "    \"prompt_input\":\n",
    "        (\"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "         \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "         \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\"),\n",
    "    \"prompt_no_input\": (\"Below is an instruction that describes a task. \"\n",
    "                        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "                        \"### Instruction:\\n{instruction}\\n\\n### Response:\"),\n",
    "}\n",
    "PROMPT_F = PROMPT_DICT[\"prompt_no_input\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bf619d0-15e4-47c4-b83d-d7ba79e0b5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputd = {\n",
    "    \"instruction\":\"你的名字是什么？\",\n",
    "}\n",
    "truly_input = PROMPT_F.format_map(inputd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a284663-e97e-4b05-9baf-0db521c72324",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "你的名字是什么？\n",
      "\n",
      "### Response:\n"
     ]
    }
   ],
   "source": [
    "print(truly_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "119b87e3-1b97-4918-9421-145faca49b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"/home/xinyu/bloomz-560m/\"\n",
    "tokenizer = BloomTokenizerFast.from_pretrained(model_path)\n",
    "base_model1 = BloomForCausalLM.from_pretrained(model_path, return_dict=True, device_map='auto')\n",
    "base_model2 = BloomForCausalLM.from_pretrained(model_path, return_dict=True, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96d29b5d-b510-49c0-9d6d-9b0e16089613",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinyu/anaconda3/envs/llm/lib/python3.10/site-packages/peft/tuners/lora.py:173: UserWarning: fan_in_fan_out is set to True but the target module is not a Conv1D. Setting fan_in_fan_out to False.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "peft_model_tutu_path = \"./outputs/tutu/\"\n",
    "peft_model_niuyeye_path = \"./outputs/niuyeye/\"\n",
    "\n",
    "tutu_model = PeftModel.from_pretrained(base_model1, peft_model_tutu_path)\n",
    "niuyeye_model = PeftModel.from_pretrained(base_model2, peft_model_niuyeye_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49c1dc49-3cac-4b1f-acc4-685a97eda7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图图模型：\n",
      " Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "你的名字是什么？\n",
      "\n",
      "### Response:我是大耳朵图图\n",
      "\n",
      "\n",
      "牛爷爷模型：\n",
      " Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "你的名字是什么？\n",
      "\n",
      "### Response:我是牛爷爷\n"
     ]
    }
   ],
   "source": [
    "question = tokenizer(truly_input, return_tensors='pt')\n",
    "\n",
    "tutu_output = tutu_model.generate(**question, max_new_tokens=50)\n",
    "niuyeye_output = niuyeye_model.generate(**question, max_new_tokens=50)\n",
    "\n",
    "print(\"图图模型：\\n\", tokenizer.decode(tutu_output[0], skip_special_tokens=True))\n",
    "print(\"\\n\\n牛爷爷模型：\\n\", tokenizer.decode(niuyeye_output[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
